# Weight-Sharing-Papers
Weight Sharing Paper list for Deep Neural Network Compression  
[![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2Fkairos03%2FWeight-Sharing-Papers&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false)](https://hits.seeyoufarm.com)

# Weight Sharing
- ACDC: Weight Sharing in Atom-Coefficient Decomposed Convolution, 2020 [[Paper](https://arxiv.org/abs/2009.02386)]
- Learning Shared Filter Bases for Efficient ConvNets, 2020 [[Paper](https://arxiv.org/abs/2006.05066)]
- Neural Epitome Search for Architecture-Agnostic Network Compression, **ICLR 2020** [[Paper](https://arxiv.org/abs/1907.05642)]
- FSNet: Compression of Deep Convolutional Neural Networks by Filter Summary, **ICLR 2020** [[Paper](https://arxiv.org/abs/1902.03264)]
- Learning Filter Basis for Convolutional Neural Network Compression, **ICCV 2019** [[Paper](https://arxiv.org/abs/1908.08932)] [[Code](https://github.com/ofsoundof/learning_filter_basis)]
- Dynamic Recursive Neural Network, **CVPR 2019** [[Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Guo_Dynamic_Recursive_Neural_Network_CVPR_2019_paper.pdf)]
- Learning Implicitly Recurrent CNNs Through Parameter Sharing, **ICLR 2019** [[Paper](https://arxiv.org/abs/1902.09701)] [[Code](https://github.com/lolemacs/soft-sharing)]

# Weight Clustering
- Deep k-Means: Re-Training and Parameter Sharing with Harder Cluster Assignments for Compressing Deep Convolutions, **ICML 2018** [[Paper](https://arxiv.org/pdf/1806.09228.pdf)] [[Code](https://github.com/VITA-Group/Deep-K-Means-pytorch)]
- Clustering Convolutional Kernels to Compress Deep Neural Networks, **ECCV 2018** [[Paper](https://cv.snu.ac.kr/publication/conf/2018/Sanghyun_Son_Clustering_Convolutional_Kernels_ECCV_2018_paper.pdf)] [[Code](https://github.com/thstkdgus35/clustering-kernels)]

# Weight Decomposition
- Stable Low-rank Tensor Decomposition for Compression of Convolutional Neural Network, **ECCV 2020** [[Paper](https://arxiv.org/abs/2008.05441)]
- PENNI: Pruned Kernel Sharing for Efficient CNN Inference, **ICML2020** [[Paper](https://arxiv.org/abs/2005.07133)] [[Code](https://github.com/timlee0212/PENNI)]
- Speeding up Convolutional Neural Networks with Low Rank Expansions, **BMVC 2014** [[Paper](https://arxiv.org/abs/1405.3866)]
